{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12120532-ac2e-4a50-8e5b-eba89e8feb7f",
   "metadata": {},
   "source": [
    "### Here we collect test target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f2df7d-852b-4cd9-b3cf-29f1e2d0f7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/jovyan/.conda/envs/python3/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-607cf2d0-f15b-429d-ab82-5dfbbca521ef;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n",
      ":: resolution report :: resolve 148ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-607cf2d0-f15b-429d-ab82-5dfbbca521ef\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/5ms)\n",
      "23/04/22 12:36:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.window import Window as w\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(\"spark.driver.memory\",\"100g\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "    .config(\"fs.s3a.aws.credentials.provider\",\"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\")\n",
    "    .config(\"spark.driver.maxResultSize\",0)\n",
    "    # .config('spark.hadoop.io.compression.codecs', 'nl.basjes.hadoop.io.compress.SplittableGzipCodec')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "spark.conf.set(\"spark.hadoop.io.compression.codecs\", \"org.apache.hadoop.io.compress.BZip2Codec\")\n",
    "\n",
    "s3_bucket_spark = \"s3a://820323602090-team-dbad373c-7e36-407b-8690-05a44b804f43\"\n",
    "s3_bucket_pandas = \"s3a://820323602090-team-dbad373c-7e36-407b-8690-05a44b804f43\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4dad94b-affb-40ec-9fef-d8002bbbc4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE DIM_DIAGNOSIS/\n",
      "                           PRE DIM_DRUG/\n",
      "                           PRE DIM_HCPT/\n",
      "                           PRE DX_DIAGNOSIS/\n",
      "                           PRE MEDICAL_HEADERS/\n",
      "                           PRE MEDICAL_SERVICE_LINES/\n",
      "                           PRE PATIENT_ENROLLMENTS/\n",
      "                           PRE PATIENT_SUMMARIES/\n",
      "                           PRE PAYERS/\n",
      "                           PRE PHARMACY/\n",
      "                           PRE PROVIDER_SUMMARIES/\n",
      "                           PRE VISIT_SUMMARIES/\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $team_bucket/data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac6b5f2-02cd-4722-b313-fe876d58b903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/22 12:37:36 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(s3_bucket_spark+\"/data/raw/PROVIDER_SUMMARIES/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c235d0a7-dbb2-46b6-8ca0-12e7b304f7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VALUE',\n",
       " 'COHORT_ID',\n",
       " 'FIRST_NAME',\n",
       " 'MIDDLE_NAME',\n",
       " 'LAST_NAME',\n",
       " 'SUFFIX',\n",
       " 'DEACTIVATION_DATE',\n",
       " 'REACTIVATION_DATE',\n",
       " 'PRIMARY_HCO_ID',\n",
       " 'PROCESS_DATE',\n",
       " 'PROVIDER_ID',\n",
       " 'PROVIDER_STATE',\n",
       " 'PROVIDER_TYPE',\n",
       " 'SPECIALTY1',\n",
       " 'SPECIALTY2',\n",
       " 'CREDENTIAL_TYPE',\n",
       " 'KCS1',\n",
       " 'KCS2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58ef52e-e47b-4f60-837d-b26edef1fddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------------+----------------+\n",
      "|               VALUE|PROVIDER_ID|       SPECIALTY1|      SPECIALTY2|\n",
      "+--------------------+-----------+-----------------+----------------+\n",
      "|{\"COHORT_ID\":1043...| 1952599888|Assistive Therapy|            null|\n",
      "|{\"COHORT_ID\":1043...| 1952599904|       Podiatrist|            null|\n",
      "|{\"COHORT_ID\":1043...| 1952599912|          Dentist|            null|\n",
      "|{\"COHORT_ID\":1043...| 1952599938|       Psychiatry|General Practice|\n",
      "|{\"COHORT_ID\":1043...| 1952599946|  Behavioral Care|            null|\n",
      "+--------------------+-----------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('VALUE', 'PROVIDER_ID', 'SPECIALTY1', 'SPECIALTY2').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff933245-a7ad-4c27-bdbf-f32c7e27f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = spark.read.parquet('../submission/submission_team_xxx.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233fb254-279e-4edf-80ad-9bc8a9937919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|PROVIDER_NPI|PROBABILITY|\n",
      "+------------+-----------+\n",
      "|  1710065842|          0|\n",
      "|  1700128584|          0|\n",
      "|  1265434021|          0|\n",
      "|  1598178329|          0|\n",
      "|  1598129975|          0|\n",
      "+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submission.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f10117b-b1cf-49de-b981-d259501fb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = submission.select('PROVIDER_NPI').join(\n",
    "    df.select('PROVIDER_ID', 'SPECIALTY2').withColumnRenamed('PROVIDER_ID', 'PROVIDER_NPI'), how='left', on='PROVIDER_NPI'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48d73b4d-40d9-435d-9686-065edc99726f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+\n",
      "|PROVIDER_NPI|       SPECIALTY2|\n",
      "+------------+-----------------+\n",
      "|  1265434021|             null|\n",
      "|  1598178329|Internal Medicine|\n",
      "|  1700128584| Surgery, General|\n",
      "|  1922045095| General Practice|\n",
      "|  1598129975|             null|\n",
      "+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===>                                                    (2 + 28) / 30]\r"
     ]
    }
   ],
   "source": [
    "test_target.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f9ce5f4-81a5-4cfe-b0de-5356ee8e0d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13416"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===>                                                    (2 + 28) / 30]\r"
     ]
    }
   ],
   "source": [
    "test_target.select('PROVIDER_NPI').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3626074e-0d39-4112-9ddc-d215057db0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===>                                                    (2 + 28) / 30]\r"
     ]
    }
   ],
   "source": [
    "test_target.write.parquet('../data/02_intermediate/test_target.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06dd786b-1415-4a51-a85c-8906307455c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23223b7-996c-4e61-8af1-b3edf8b84405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
